{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the MIT License.\n",
    "# Build an Azure Machine Learning pipeline for batch scoring\n",
    "\n",
    "<b>Note:</b>\n",
    "\n",
    "Select Kernel = Python 3.6 - Azure ML when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you learn how to build an Azure Machine Learning pipeline to run a batch scoring job. Machine learning pipelines optimize your workflow with speed, portability, and reuse, so you can focus on machine learning instead of infrastructure and automation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example uses a pretrained Inception-V3 convolutional neural network model implemented in Tensorflow to classify unlabeled images.\n",
    "\n",
    "In this lab, you complete the following tasks:\n",
    "\n",
    "- Configure workspace\n",
    "- Download and store sample data\n",
    "- Create dataset objects to fetch and output data\n",
    "- Download, prepare, and register the model in your workspace\n",
    "- Use provisioned compute target and create a scoring script\n",
    "- Use the ParallelRunStep class for async batch scoring\n",
    "\n",
    "\n",
    "The batch scoring example in this tutorial uses only one pipeline step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace and create a datastore\n",
    "Create a workspace object from the existing Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This code snippet expects the workspace configuration to be saved in the current directory or its parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a datastore for sample images\n",
    "\n",
    "get the ImageNet evaluation public data sample from the sampledata public blob container. Call register_azure_blob_container() to make the data available to the workspace under the name images_datastore. Then, set the workspace default datastore as the output datastore. Use the output datastore to score output in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "batchscore_blob = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=\"images_datastore\", \n",
    "                      container_name=\"sampledata\", \n",
    "                      account_name=\"pipelinedata\", \n",
    "                      overwrite=True)\n",
    "\n",
    "def_data_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset objects\n",
    "When building pipelines, Dataset objects are used for reading data from workspace datastores, and PipelineData objects are used for transferring intermediate data between pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, you create Dataset objects that correspond to the datastore directories for both the input images and the classification labels (y-test values). You also create a PipelineData object for the batch scoring output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "input_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\n",
    "label_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\n",
    "output_dir = PipelineData(name=\"scores\", \n",
    "                          datastore=def_data_store, \n",
    "                          output_path_on_compute=\"batchscoring/results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the datasets to the workspace if you want to reuse it later. This step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.register(workspace = ws, name = \"input_images\")\n",
    "label_ds = label_ds.register(workspace = ws, name = \"label_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and register the model\n",
    "\n",
    "Download the pretrained Tensorflow model to use it for batch scoring in a pipeline. First, create a local directory where you store the model. Then, download and extract the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "    \n",
    "response = urllib.request.urlretrieve(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\", \"model.tar.gz\")\n",
    "tar = tarfile.open(\"model.tar.gz\", \"r:gz\")\n",
    "tar.extractall(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, register the model to your workspace, so you can easily retrieve the model in the pipeline process. In the register() static function, the model_name parameter is the key you use to locate your model throughout the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    " \n",
    "model = Model.register(model_path=\"models/inception_v3.ckpt\",\n",
    "                       model_name=\"inception\",\n",
    "                       tags={\"pretrained\": \"inception\"},\n",
    "                       description=\"Imagenet trained tensorflow inception\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach the remote compute target\n",
    "Machine learning pipelines can't be run locally, so you run them on cloud resources or remote compute targets. A remote compute target is a reusable virtual compute environment where you run experiments and machine learning workflows.\n",
    "<br><br>\n",
    "Update compute target name in cell below before executing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = ws.compute_targets['CPU-Cluster-XX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the scoring, create a batch scoring script called batch_scoring.py, and then write it to the current directory. The script takes input images, applies the classification model, and then outputs the predictions to a results file.\n",
    "\n",
    "The batch_scoring.py script takes the following parameters, which get passed from the ParallelRunStep you create later:\n",
    "\n",
    "- --model_name: The name of the model being used.\n",
    "- --labels_dir: The location of the labels.txt file.\n",
    "<br><br>\n",
    "The pipeline infrastructure uses the ArgumentParser class to pass parameters into pipeline steps. For example, in the following code, the first argument --model_name is given the property identifier model_name. In the init() function, Model.get_model_path(args.model_name) is used to access this property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile batch_scoring.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception_v3\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "image_size = 299\n",
    "num_channel = 3\n",
    "\n",
    "\n",
    "def get_class_label_dict(labels_dir):\n",
    "    label = []\n",
    "    labels_path = os.path.join(labels_dir, 'labels.txt')\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(labels_path).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "\n",
    "def init():\n",
    "    global g_tf_sess, probabilities, label_dict, input_images\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Start a tensorflow model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    parser.add_argument('--labels_dir', dest=\"labels_dir\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    label_dict = get_class_label_dict(args.labels_dir)\n",
    "    classes_num = len(label_dict)\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        input_images = tf.placeholder(tf.float32, [1, image_size, image_size, num_channel])\n",
    "        logits, _ = inception_v3.inception_v3(input_images,\n",
    "                                              num_classes=classes_num,\n",
    "                                              is_training=False)\n",
    "        probabilities = tf.argmax(logits, 1)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    g_tf_sess = tf.Session(config=config)\n",
    "    g_tf_sess.run(tf.global_variables_initializer())\n",
    "    g_tf_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(g_tf_sess, model_path)\n",
    "\n",
    "\n",
    "def file_to_tensor(file_path):\n",
    "    image_string = tf.read_file(file_path)\n",
    "    image = tf.image.decode_image(image_string, channels=3)\n",
    "\n",
    "    image.set_shape([None, None, None])\n",
    "    image = tf.image.resize_images(image, [image_size, image_size])\n",
    "    image = tf.divide(tf.subtract(image, [0]), [255])\n",
    "    image.set_shape([image_size, image_size, num_channel])\n",
    "    return image\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    result_list = []\n",
    "    for file_path in mini_batch:\n",
    "        test_image = file_to_tensor(file_path)\n",
    "        out = g_tf_sess.run(test_image)\n",
    "        result = g_tf_sess.run(probabilities, feed_dict={input_images: [out]})\n",
    "        result_list.append(os.path.basename(file_path) + \": \" + label_dict[result[0]])\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efore you run the pipeline, create an object that defines the Python environment and creates the dependencies that your batch_scoring.py script requires. The main dependency required is Tensorflow, but you also install azureml-core and azureml-dataprep[fuse] which are required by ParallelRunStep.Also, specify Docker and Docker-GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.15.2\",\n",
    "                                            \"azureml-core\", \"azureml-dataprep[fuse]\"])\n",
    "env = Environment(name=\"parallelenv\")\n",
    "env.python.conda_dependencies = cd\n",
    "env.docker.base_image = DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the configuration to wrap the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    environment=env,\n",
    "    entry_script=\"batch_scoring.py\",\n",
    "    source_directory=\".\",\n",
    "    output_action=\"append_row\",\n",
    "    mini_batch_size=\"20\",\n",
    "    error_threshold=1,\n",
    "    compute_target=compute_target,\n",
    "    process_count_per_node=2,\n",
    "    node_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline step is an object that encapsulates everything you need to run a pipeline, including:\n",
    "\n",
    "- Environment and dependency settings\n",
    "- The compute resource to run the pipeline on\n",
    "- Input and output data, and any custom parameters\n",
    "- Reference to a script or SDK logic to run during the step\n",
    "\n",
    "Multiple classes inherit from the parent class PipelineStep. You can choose classes to use specific frameworks or stacks to build a step. In this example, you use the ParallelRunStep class to define your step logic by using a custom Python script. If an argument to your script is either an input to the step or an output of the step, the argument must be defined both in the arguments array and in either the input or the output parameter, respectively.\n",
    "\n",
    "In scenarios where there is more than one step, an object reference in the outputs array becomes available as an input for a subsequent pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "from datetime import datetime\n",
    "\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "label_config = label_ds.as_named_input(\"labels_input\")\n",
    "\n",
    "batch_score_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    inputs=[input_images.as_named_input(\"input_images\")],\n",
    "    output=output_dir,\n",
    "    arguments=[\"--model_name\", \"inception\",\n",
    "               \"--labels_dir\", label_config],\n",
    "    side_inputs=[label_config],\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the pipeline. First, create a Pipeline object by using your workspace reference and the pipeline step you created. The steps parameter is an array of steps. In this case, there's only one step for batch scoring. To build pipelines that have multiple steps, place the steps in order in this array.\n",
    "\n",
    "Next, use the Experiment.submit() function to submit the pipeline for execution. The wait_for_completion function outputs logs during the pipeline build process. You can use the logs to see current progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "pipeline_run = Experiment(ws, 'Lab-05-batch_scoring').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_run = next(pipeline_run.get_children())\n",
    "batch_output = batch_run.get_output_data(\"scores\")\n",
    "batch_output.download(local_path=\"inception_results\")\n",
    "\n",
    "for root, dirs, files in os.walk(\"inception_results\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"parallel_run_step.txt\"):\n",
    "            result_file = os.path.join(root, file)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"Filename\", \"Prediction\"]\n",
    "print(\"Prediction has \", df.shape[0], \" rows\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- End ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Increase width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 (amllabs)",
   "language": "python",
   "name": "amllabs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
